{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS229_LSTM_v3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGA_Ac_acbAt"
      },
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import *\n",
        "from keras.callbacks import ReduceLROnPlateau \n",
        "from matplotlib import pyplot\n",
        "\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#import LMPs\n",
        "#df = pd.read_csv('/content/drive/MyDrive/CS229_Project/pacifica_oct_lmp.csv')\n",
        "df = pd.read_csv('/content/drive/MyDrive/CS229_Project/bellehaven_2019.csv')\n",
        "\n",
        "#import temperature data\n",
        "temp = pd.read_csv('/content/drive/MyDrive/CS229_Project/merced_temp.csv')\n",
        "images_dir = '/content/drive/MyDrive/CS229_Project'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IPh8jdWcyWn"
      },
      "source": [
        "\n",
        "def train_test_split(df, temps, train_test_split=0.8):\n",
        "  num_train = round(train_test_split * df.shape[0])\n",
        "  training_set = np.zeros((num_train,2))\n",
        "  training_set[:num_train,0] = df.iloc[:num_train, 1].values\n",
        "  training_set[:num_train,1] = temps[:num_train]\n",
        "  test_set = np.zeros((len(temps)-num_train,2))\n",
        "  test_set[:,0] = df.iloc[num_train:, 1].values\n",
        "  test_set[:,1] = temps[num_train:]\n",
        "  return training_set, test_set, num_train\n",
        "\n",
        "def resize_scale(training_set, test_set):\n",
        "  #perform the feature scaling using the minmaxscaler from sklearn\n",
        "  minmaxscale = MinMaxScaler(feature_range = (0, 1))\n",
        "  scaled_train = minmaxscale.fit_transform(training_set)\n",
        "  return scaled_train, minmaxscale\n",
        "\n",
        "\n",
        "def data_shift(scaled_train, num_train, sequence_length=40, shift=1, num_features=2):\n",
        "  #extract x train from price and temperature data and y train from the price data, shift by 1 \n",
        "  X_train = np.zeros((num_train-sequence_length,sequence_length-shift,num_features))\n",
        "  for i in range(sequence_length, num_train):\n",
        "      X_train[i-sequence_length,:,0] = scaled_train[i-(sequence_length-shift):i, 0]\n",
        "      X_train[i-sequence_length,:,1] = scaled_train[i-(sequence_length-shift):i, 1]\n",
        "  y_train = scaled_train[sequence_length:num_train,0]\n",
        "  return X_train, y_train\n",
        "\n",
        "def LSTM_model(X_train):\n",
        "  #define LSTM model with keras\n",
        "  model = Sequential()\n",
        "\n",
        "  # LSTM layer 1 and dropout regularization\n",
        "  model.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  # LSTM layer 2 and dropout regularization\n",
        "  model.add(LSTM(units = 50, return_sequences = True))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  # LSTM layer 3 and dropout regularization\n",
        "  model.add(LSTM(units = 50))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  # Output layer\n",
        "  model.add(Dense(units = 1))\n",
        "\n",
        "  #compile the model\n",
        "  model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "  learning_rate = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=100)\n",
        "  return model, learning_rate\n",
        "\n",
        "def shift_test(df, temps, num_train,  minmaxscale, sequence_length=40,shift=1, num_features=2):\n",
        "  #construct entire dataset\n",
        "  dataset_total = np.zeros((len(temps),2))\n",
        "  dataset_total[:,0] = df.iloc[:, 1].values\n",
        "  dataset_total[:,1] = temps[:]\n",
        "\n",
        "  #construct test set\n",
        "  test_set = np.zeros((len(temps)-num_train,2))\n",
        "  test_set[:,0] = df.iloc[num_train:, 1].values\n",
        "  test_set[:,1] = temps[num_train:]\n",
        "\n",
        "  test_in = dataset_total[len(dataset_total) - len(test_set) - sequence_length:]\n",
        "  test_in = minmaxscale.transform(test_in)\n",
        "\n",
        "  #shift test set by lags\n",
        "  X_test = np.zeros((len(test_set),sequence_length-shift,num_features))\n",
        "  for i in range(sequence_length, len(test_set)+sequence_length):\n",
        "      X_test[i-sequence_length,:,0] = test_in[i-(sequence_length-shift):i, 0]\n",
        "      X_test[i-sequence_length,:,1] = test_in[i-(sequence_length-shift):i, 1]\n",
        "\n",
        "  #make data arrays\n",
        "  X_test = np.array(X_test)\n",
        "  return X_test, test_set\n",
        "\n",
        "def inverse_predictions(X_test):\n",
        "  predicted_price = model.predict(X_test)\n",
        "  predicted_price_t = np.zeros((len(predicted_price),2))\n",
        "  new_temp = np.resize(predicted_price,(len(predicted_price),))\n",
        "  predicted_price_t[:,0] = new_temp\n",
        "  predicted_price_t[:,1] = new_temp\n",
        "  predicted_price = minmaxscale.inverse_transform(predicted_price_t)\n",
        "  return predicted_price\n",
        "\n",
        "def RMSE(actual, predicted):\n",
        "  # calculate RMSE\n",
        "  rmse = sqrt(mean_squared_error(actual, predicted))\n",
        "  print('Test RMSE: %.3f' % rmse)\n",
        "  return rmse\n",
        "\n",
        "def plot_func(actual, predicted):\n",
        "  # Plotting predicted vs actual price\n",
        "  plt.plot(actual[:,0], label = 'Real Price')\n",
        "  plt.plot(predicted[:,0], color='red', label = 'Predicted Price')\n",
        "  plt.title('LSTM LMP Price Prediction')\n",
        "  plt.xlabel('Time [days]')\n",
        "  plt.xticks(ticks=np.arange(0, len(predicted), 96), labels=[4*int(x) for x in np.arange(0, len(predicted), 24)/24])\n",
        "  plt.ylabel('Price [$]')\n",
        "  plt.legend()\n",
        "  #plt.savefig(f\"{images_dir}/LSTM_LMP_twofeatures_100epochs_lag1.png\", dpi=500) \n",
        "  plt.show()\n",
        "\n",
        "def plot_loss(model_params):\n",
        "  # Plot the losses over the epochs\n",
        "  plt.clf()\n",
        "  plt.plot(model_params.history['loss'])\n",
        "  plt.plot(model_params.history['val_loss'])\n",
        "  plt.title('Model Loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Training Data', 'Validation Data'], loc='upper right')\n",
        "\n",
        "  images_dir = '/content/drive/MyDrive/CS229_Project'\n",
        "  #plt.savefig(f\"{images_dir}/LSTM_loss_2features_100epochs_lag1.png\", dpi=500) \n",
        "\n",
        "  plt.show()\n",
        "\n",
        "def plot_temp(temp_test):\n",
        "  #plot temperature data for visualization purposes\n",
        "  plt.clf()\n",
        "  plt.plot(temp_test[:,1])\n",
        "\n",
        "  plt.ylabel('temp (C)')\n",
        "  plt.xlabel('time (hrs)')\n",
        "  plt.legend(['Temp'], loc='upper right')\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "#preprocess temperatures from dataset\n",
        "temps = temp.iloc[:,2].values\n",
        "temps[temps<-20] = 0\n",
        "\n",
        "training_set, test_set, num_train = train_test_split(df, temps)\n",
        "scaled_train, minmaxscale = resize_scale(training_set, test_set)\n",
        "X_train, y_train = data_shift(scaled_train, num_train)\n",
        "model, learning_rate = LSTM_model(X_train)\n",
        "epochs=100\n",
        "batch_size=32\n",
        "validation=.05\n",
        "model_params=model.fit(X_train, y_train, batch_size, epochs, validation_split = validation, callbacks = [learning_rate])\n",
        "X_test, y_test=shift_test(df, temps, num_train, minmaxscale)\n",
        "predicted=inverse_predictions(X_test)\n",
        "RMSE(y_test, predicted)\n",
        "plot_func(y_test, predicted)\n",
        "plot_loss(model_params)\n",
        "plot_temp(y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}